---
layout: page
permalink: /cfp
title: "Call for Papers"
nav: true
---

<!-- Despite rapid advances in machine learning, solving large-scale stochastic dynamic programming problems remains a significant challenge. The combination of neural networks with RL has opened new avenues for algorithm design, but the lack of theoretical guarantees of these approaches hinders their applicability to high-stake problems traditionally addressed using control theory, such as online supply chain optimization, industrial automation, and adaptive transportation systems. This workshop focuses on recent advances in developing a learning theory of decision (control) systems, that builds on techniques and concepts from two communities that historically had limited interactions despite their shared goals: Reinforcement learning (RL) and control theory. -->

This workshop aims to connect reinforcement learning and control theory, and bring together researchers from both fields. In particular, we invite contributions on all fundamental and theoretical aspects, with a special emphasis on topics that connect both fields and provide new perspectives. Contributions that bridge theory and applications are also welcome. We believe that significant progress in tackling large-scale applications can only be achieved through collaborative efforts and a mutual understanding of each field's strengths and approaches. Our workshop is dedicated to fostering dialogue and collaboration, paving the way for breakthroughs in complex dynamic programming challenges and interactive systems.

We invite researchers to submit papers on the topics listed below. All accepted papers will be presented as posters or selected for contributed talks. There will be no proceedings, however, accepted papers will be made available through the OpenReview website. We allow submission of published or already peer-reviewed papers but we ask authors to indicate this in the submission form for transparency.


### Topics


Technical topics include, but are not limited to, the following aspects:

- *Performance measures and guarantees:* Stability, robustness, regret bounds, sample-complexity, stochastic vs non-stochastic approaches, MDPs etc.
- *Fundamental assumptions:* Linear and non-linear systems, excitation, stability, etc.
- *Fundamental limits:* Results that mathematically characterize the difficulty of a given problem, statistical, information theoretic and computational lower bounds.
- *Computational aspects:* Efficient algorithms, computational hardness, approximations, etc.
- *Topology:* Continuous-state and action spaces vs discrete spaces; Discrete and continuous time analysis.
- *Models:* Bandits, Markov Decision Processes, Linear and nonlinear control, partial observability, POMDPs, partial monitoring, etc
- *Data Acquisition & Exploration:* Exploration-exploitation trade-offs, pure-exploration, experimental design.
- *Offline vs. online:* Open-loop and closed loop control, offline and online reinforcement learning and hybrid approaches.
- *Planning and learned search:* Dynamic programming, tree search and planning algorithms.
- *Target applications:* Formalization of applications such as autonomous vehicles, robots, industrial processes, recommender systems, internet routing, hardware optimization, hyper-parameter optimization and AutoML â€¦
- *Benchmarks:* Evaluation of algorithms and theoretical results on a suitable collection of problems.



## Important Dates

__Submission Deadline:__ May 27, 2024 (AoE) <br>
__Acceptance Notification:__ June 17, 2024 (AoE)<br>
__Camera Ready:__ tbd<br>
__Workshop:__ During the ICML 24 workshops from July 26 - 27, 2024. Exact dates will be announced soon.<br>

## Submission Instructions

__Formatting:__ We have a short and long submission track:
* Short format: Up to 4 pages plus references and appendix.
* Long format: Up to 8 pages plus references and appendix.

__Submission:__ via our [OpenReview site](https://openreview.net/group?id=ICML.cc/2024/Workshop/RLControlTheory) <br>
__Template:__ tbd<br>
__Reviews:__ Submissions will be evaluated by a reviewing committee. There will be a single round of reviews and no author response.<br>